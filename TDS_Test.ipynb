{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path1 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\MDX4806-20160817081259226.TDS'\n",
    "path2 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX4806\\MDX4806-20160817095942791.TDS'\n",
    "gz1 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\SNK1551-20160602193817305.TDS.gz'\n",
    "\n",
    "def transform_tds(gz_path):\n",
    "    '''\n",
    "    transform gz TDS file with desired format for Hive\n",
    "    '''\n",
    "    tags, svid = [], {}\n",
    "    with gzip.open(gz_path, 'rb') as f:        \n",
    "        with open(gz_path[0:-6]+'txt', 'w') as fw:\n",
    "#             fw.write('%s\\t%s\\t%s\\n' %('timestamp', 'context', 'data')) -- no need for hive\n",
    "            for l in f.read().split('\\n'):                \n",
    "                elem = l.split(' ')\n",
    "                # buffering tag\n",
    "                if l.startswith('TAG'):                    \n",
    "                    ctx = elem[1][6:elem[1].rfind('/')].replace('Eqp:','').replace('PA:','').replace('SPA:','')\n",
    "                    svid[elem[2][5:]] = ctx\n",
    "                    tags.append((l,ctx))\n",
    "                # parsing value line\n",
    "                if l.startswith('TD'):                    \n",
    "                    ts = elem[1][3:].replace('-',' ').replace('/','-')\n",
    "                    # write buffered tag line with timestamp and context\n",
    "                    for t,ctx in tags:\n",
    "                        fw.write('%s\\t%s\\t%s' %(ts, ctx, t))\n",
    "                    tags = []\n",
    "                    # write value line\n",
    "                    sn = elem[2][4:-1].split('^')[0].split('=')[0]                \n",
    "                    fw.write('%s\\t%s\\t%s' %(ts, svid[sn], l))\n",
    "    print 'TDS transform completed!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "gz1 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\SNK1551-20160602193817305.TDS.gz'\n",
    "gz2 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\ETX4800-20160817091159382.TDS.gz'\n",
    "\n",
    "def transform_tds_gz(gz_path):\n",
    "    '''\n",
    "    transform gz TDS file with desired format for Hive\n",
    "    '''\n",
    "    tags, svid, gz_out = [], {}, []\n",
    "    with gzip.open(gz_path, 'rb') as f:        \n",
    "        for l in f.read().split('\\n'):                \n",
    "            elem = l.split(' ')\n",
    "            # buffering tag\n",
    "            if l.startswith('TAG'):                    \n",
    "                ctx = elem[1][6:elem[1].rfind('/')].replace('Eqp:','').replace('PA:','').replace('SPA:','').replace('/','_')\n",
    "                svid[elem[-2][5:]] = ctx\n",
    "                tags.append((l,ctx))\n",
    "            # parsing value line\n",
    "            if l.startswith('TD'):                    \n",
    "                ts = elem[1][3:].replace('-',' ').replace('/','-')\n",
    "                # write buffered tag line with timestamp and context\n",
    "                for t,ctx in tags:\n",
    "                    gz_out.append('%s\\t%s\\t%s' %(ts, ctx, t))\n",
    "                tags = []\n",
    "                # write value line\n",
    "                sn = elem[2][4:-1].split('^')[0].split('=')[0]                \n",
    "                gz_out.append('%s\\t%s\\t%s' %(ts, svid[sn], l))\n",
    "            \n",
    "    with gzip.open(gz_path[0:-6]+'gz', 'wb') as f:\n",
    "        f.write('\\n'.join(gz_out))\n",
    "    print 'TDS transform completed for %s' %gz_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-08-17 08:02:19.621',\n",
       " 'MDX4806/CHD',\n",
       " 'TD TS=2016/08/17-08:02:19.621 SV={3=0^4=-1^5=29.741^6=\"HEAT\"^7=3^8=0.656^9=309^10=16.5678884243294^11=-0.06^12=1800^13=8.054^14=3.27413814835256E-05^15=7.498779296875^16=3.736^17=-0.000367^18=-2.3E-05^19=-0.000397^20=-3.3E-05^21=0.000227^22=3.4E-05^23=-4.6E-05^24=0.000139}']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d='2016/08/17-08:02:19.621\tMDX4806/CHD\tTAG NAME=\"Eqp:MDX4806/PA:CHD/BR2_LCF--rCfXCorrExt\" SVID=21 UNITS=\"m\"'\n",
    "e='timestamp\tcontext\tdata'\n",
    "f='2016-08-17 08:02:19.621\tMDX4806/CHD\tTD TS=2016/08/17-08:02:19.621 SV={3=0^4=-1^5=29.741^6=\"HEAT\"^7=3^8=0.656^9=309^10=16.5678884243294^11=-0.06^12=1800^13=8.054^14=3.27413814835256E-05^15=7.498779296875^16=3.736^17=-0.000367^18=-2.3E-05^19=-0.000397^20=-3.3E-05^21=0.000227^22=3.4E-05^23=-4.6E-05^24=0.000139}'\n",
    "f.split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDS transform completed for C:\\Users\\leyang\\Downloads\\AAA_MDX\\ETX4800-20160817091159382.TDS.gz\n",
      "--- 1.21299982071 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "transform_tds_gz(gz2)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='TD TS=2016/08/17-08:02:19.621 SV={3=0^4=-1^5=29.741^6=\"HEAT\"^7=3^8=0.656^9=309^10=16.5678884243294^11=-0.06^12=1800^13=8.054^14=3.27413814835256E-05^15=7.498779296875^16=3.736^17=-0.000367^18=-2.3E-05^19=-0.000397^20=-3.3E-05^21=0.000227^22=3.4E-05^23=-4.6E-05^24=0.000139}'\n",
    "b='TD TS=2016/08/17-08:02:19.851 SV={2=\"ProcessStarted\"}'\n",
    "b='TD TS=2016/08/17-08:02:19.861 SV={1=0}'\n",
    "b.split(' ')[2][4:-1].split('^')[0].split('=')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "with gzip.open('C:\\Users\\leyang\\Downloads\\AAA_MDX\\SNK1551-20160602193817305.TDS.gz', 'rb') as f:\n",
    "    file_content = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip, re\n",
    "import numpy as np\n",
    "\n",
    "sample_tag = 'TAG NAME=\"Eqp:SNK1551/PA:PM3L/ExhaustPressure02\" SVID=58 UNITS=\"\"'\n",
    "sample_td = ' TD TS=2016/06/02-23:12:35.714 SV={191=\"SNK1551-20160602-0032\"^192=\"UR62192.000\"^193=\"rcp P-SC-50DHF-180TMAH-5L20P\"^194=\"D-P-SNK155X. P-SC-50DHF-180TMAH-HS.01\"^195=\"21\"^196=\"PMGYB060MXA7\"^198=1^201=1}'\n",
    "\n",
    "p_tag = re.compile('TAG NAME=\"Eqp:(.*)\" SVID=(\\d*) UNITS=\"(.*)\"')\n",
    "p_td = re.compile('TD TS=(.*) SV={(.*)}')\n",
    "\n",
    "gz1 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\SNK1551-20160602193817305.TDS.gz'\n",
    "\n",
    "def check_tds_gz(gz_path):\n",
    "    '''\n",
    "    transform gz TDS file with desired format for Hive\n",
    "    '''\n",
    "    tags, svid, gz_out, cnt = [], {}, [], 0\n",
    "    fid = gz_path[gz_path.index('-')+1:-7]\n",
    "    with gzip.open(gz_path, 'rb') as f:        \n",
    "        for l in f.read().split('\\n'):   \n",
    "            # buffering tag\n",
    "            if l.startswith('TAG'):       \n",
    "                p1, p2 = l.index('\" SVID='), l.index(' UNITS=\"')\n",
    "                tag, sid = l[10:p1], l[p1+7:p2]\n",
    "                ctx = tag[:tag.rfind('/')].replace('Eqp:','').replace('PA:','').replace('SPA:','').replace('/','_')\n",
    "                svid[sid] = ctx\n",
    "                tags.append((l,ctx))\n",
    "            # parsing value line\n",
    "            if l.startswith('TD'):                    \n",
    "                p1 = l.index(' SV=')\n",
    "                timestamp, sv = l[6:p1], l[p1+1:]                \n",
    "                ts = timestamp.replace('-',' ').replace('/','-')\n",
    "                # write buffered tag line with timestamp and context\n",
    "                for t,ctx in tags:\n",
    "#                     print '%s\\t%s\\t%s\\t%s' %(ts, ctx, fid, t)\n",
    "                    gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, ctx, fid, t))\n",
    "                tags = []\n",
    "                # check if all values from the same chamber, write value line\n",
    "                values = np.array(sv[4:-1].split('^'))\n",
    "                sn = np.array([svid[kv.split('=')[0]] for kv in values])\n",
    "                # split the TD row for individual chamber\n",
    "                a_ctx = np.unique(sn)                \n",
    "                if a_ctx.size > 1:\n",
    "                    cnt += 1\n",
    "#                     print (timestamp, a_ctx.size)\n",
    "                    for ctx in a_ctx:\n",
    "                        td = 'TD TS=%s SV={%s}' %(timestamp, '^'.join(values[sn==ctx]).strip('}'))\n",
    "                        gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, ctx, fid, td))\n",
    "                else:\n",
    "                    gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, a_ctx[0], fid, l))\n",
    "            \n",
    "    with gzip.open(gz_path[0:-6]+'gz', 'wb') as f:\n",
    "        f.write('\\n'.join(gz_out))\n",
    "    print 'TDS transform completed for \"%s\", with %d mixing TD lines.' %(gz_path, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\BBB\\MDX4806\\MDX4806-20160817080219812.TDS.gz\", with 3205 mixing TD lines.\n"
     ]
    }
   ],
   "source": [
    "gz2 = 'C:\\GFApps\\TDSParsing\\AAA\\ETX4800\\ETX4800-20160817075058359.TDS.gz'\n",
    "gz3 = 'C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817090432846.TDS.gz'\n",
    "gz4 = 'C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602202022427.TDS.gz'\n",
    "gz5 = 'C:\\GFApps\\TDSParsing\\BBB\\MDX4806\\MDX4806-20160817080219812.TDS.gz'\n",
    "check_tds_gz(gz5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602193817305.TDS.gz\", with 1 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602195917496.TDS.gz\", with 2 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602202022427.TDS.gz\", with 2 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602204112409.TDS.gz\", with 4 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602210222502.TDS.gz\", with 5 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602212201047.TDS.gz\", with 3 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602215613444.TDS.gz\", with 2 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602221723473.TDS.gz\", with 3 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602223818508.TDS.gz\", with 6 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602225923363.TDS.gz\", with 5 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602232024726.TDS.gz\", with 3 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602234113623.TDS.gz\", with 4 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602235008793.TDS.gz\", with 0 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160603002414090.TDS.gz\", with 3 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160603004421775.TDS.gz\", with 3 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160603010517903.TDS.gz\", with 1 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160603012626850.TDS.gz\", with 3 mixing TD lines.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = 'C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\\\'\n",
    "\n",
    "for f in os.listdir(folder):\n",
    "    if not f.endswith('.TDS.gz'):\n",
    "        continue\n",
    "    check_tds_gz(folder + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'asdfsfaf'\n",
    "s.endswith('af')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another way of parsing using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip, re\n",
    "import numpy as np\n",
    "\n",
    "gz1 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\SNK1551-20160602193817305.TDS.gz'\n",
    "\n",
    "def check_tds_gz(gz_path):\n",
    "    '''\n",
    "    transform gz TDS file with desired format for Hive\n",
    "    '''\n",
    "    \n",
    "    p_tag = re.compile('TAG NAME=\"(.*)\" SVID=(\\d*) UNITS=\"(.*)\"')\n",
    "    p_td = re.compile('TD TS=(.*) SV={(.*)}')\n",
    "    \n",
    "    tags, svid, gz_out, cnt = [], {}, [], 0\n",
    "    fid = gz_path[gz_path.index('-')+1:-7]\n",
    "    with gzip.open(gz_path, 'rb') as f:        \n",
    "        for l in f.read().split('\\n'):   \n",
    "            # buffering tag\n",
    "            if l.startswith('TAG'):       \n",
    "                tag, sid, unit = p_tag.match(l).groups()\n",
    "                ctx = '_'.join([x.split(':')[1] for x in tag.split('/')[:-1]])\n",
    "                svid[sid] = ctx\n",
    "                tags.append((l, ctx))\n",
    "            # parsing value line\n",
    "            if l.startswith('TD'):    \n",
    "                timestamp, sv = p_td.match(l).groups()\n",
    "                ts = timestamp.replace('-',' ').replace('/','-')\n",
    "                # write buffered tag line with timestamp and context\n",
    "                for t,ctx in tags:\n",
    "                    gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, ctx, fid, t))\n",
    "                tags = []\n",
    "                # check if all values from the same chamber, write value line\n",
    "                values = np.array(sv.split('^'))\n",
    "                sn = np.array([svid[kv.split('=')[0]] for kv in values])\n",
    "                # split the TD row for individual chamber\n",
    "                a_ctx = np.unique(sn)                \n",
    "                if a_ctx.size > 1:\n",
    "                    cnt += 1\n",
    "#                     print (timestamp, a_ctx.size)\n",
    "                    for ctx in a_ctx:\n",
    "                        td = 'TD TS=%s SV={%s}' %(timestamp, '^'.join(values[sn==ctx]))\n",
    "                        gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, ctx, fid, td))\n",
    "                else:\n",
    "                    gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, a_ctx[0], fid, l))\n",
    "            \n",
    "    with gzip.open(gz_path[0:-6]+'gz', 'wb') as f:\n",
    "        f.write('\\n'.join(gz_out))\n",
    "    print 'Done for \"%s\", with %d mixing TD lines.' %(gz_path, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821040152100.TDS.gz\", with 100 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821042253779.TDS.gz\", with 103 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821044354671.TDS.gz\", with 106 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821050451740.TDS.gz\", with 108 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821052552791.TDS.gz\", with 108 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821054652203.TDS.gz\", with 102 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821060753897.TDS.gz\", with 113 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821062852949.TDS.gz\", with 114 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821064957000.TDS.gz\", with 106 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821070953097.TDS.gz\", with 109 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821073056426.TDS.gz\", with 117 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821075152344.TDS.gz\", with 100 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821083257355.TDS.gz\", with 94 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821085357774.TDS.gz\", with 98 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821091457774.TDS.gz\", with 97 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821093459155.TDS.gz\", with 102 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821095457990.TDS.gz\", with 93 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821101557984.TDS.gz\", with 103 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821103700706.TDS.gz\", with 101 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821105757987.TDS.gz\", with 101 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821111900297.TDS.gz\", with 103 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821114001537.TDS.gz\", with 74 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821120058556.TDS.gz\", with 84 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821122158555.TDS.gz\", with 87 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821124259560.TDS.gz\", with 81 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821130358550.TDS.gz\", with 94 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821132458551.TDS.gz\", with 99 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821134503485.TDS.gz\", with 103 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821140602931.TDS.gz\", with 107 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821142700999.TDS.gz\", with 107 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821144803637.TDS.gz\", with 108 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821150901163.TDS.gz\", with 109 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821153003932.TDS.gz\", with 108 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821155058536.TDS.gz\", with 106 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821161103821.TDS.gz\", with 104 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821163102148.TDS.gz\", with 102 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821165204200.TDS.gz\", with 108 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821171305252.TDS.gz\", with 112 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821173404665.TDS.gz\", with 97 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821175504812.TDS.gz\", with 102 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821181605865.TDS.gz\", with 100 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821183705445.TDS.gz\", with 106 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821185805062.TDS.gz\", with 96 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821191903112.TDS.gz\", with 103 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821194007616.TDS.gz\", with 104 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821200107668.TDS.gz\", with 106 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821202107623.TDS.gz\", with 102 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821204109583.TDS.gz\", with 89 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821210209591.TDS.gz\", with 92 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821212210084.TDS.gz\", with 82 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821214310095.TDS.gz\", with 94 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821222509086.TDS.gz\", with 105 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821224609081.TDS.gz\", with 107 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821230709079.TDS.gz\", with 104 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821232809078.TDS.gz\", with 104 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160821234911035.TDS.gz\", with 105 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822001009072.TDS.gz\", with 100 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822003111401.TDS.gz\", with 100 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822005209284.TDS.gz\", with 110 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822011211351.TDS.gz\", with 100 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822013313558.TDS.gz\", with 98 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822015414250.TDS.gz\", with 110 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822021511047.TDS.gz\", with 116 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822023611621.TDS.gz\", with 108 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822025711777.TDS.gz\", with 97 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822031809054.TDS.gz\", with 100 mixing TD lines.\n",
      "Done for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822033914352.TDS.gz\", with 101 mixing TD lines.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = 'C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\\\'\n",
    "\n",
    "for f in os.listdir(folder):\n",
    "    if not f.endswith('.TDS.gz'):\n",
    "        continue\n",
    "    check_tds_gz(folder + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive result sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file C:\\GFApps\\TDSParsing\\AAA\\q_test is good\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "aaa = '2016-08-17 08:43:30.681\tTAG NAME=\"Eqp:EPI1200/PA:CHD/BottomPyrometerValue\" SVID=447 UNITS=\"\"\t20160817090432846'\n",
    "\n",
    "aaa.split('\\t')\n",
    "\n",
    "path = 'C:\\GFApps\\TDSParsing\\AAA\\q_test'\n",
    "\n",
    "def afterCheck(path):\n",
    "    '''\n",
    "    '''\n",
    "    p_tag = re.compile('TAG NAME=\"(.*)\" SVID=(\\d*) UNITS=\"(.*)\"')\n",
    "    p_td = re.compile('TD TS=(.*) SV={(.*)}') \n",
    "    tags = {}\n",
    "    with open(path) as f:\n",
    "        for l in f.readlines():\n",
    "            ts, line, fid = l.split('\\t')\n",
    "            if line.startswith('TAG'):\n",
    "                tag, svid, unit = p_tag.match(line).groups()\n",
    "                tags[svid] = tag            \n",
    "#                 print(tag,svid,unit)\n",
    "            if line.startswith('TD'):\n",
    "                ts, vals = p_td.match(line).groups()\n",
    "                sid = [v.split('=')[0] in tags for v in vals.split('^')]\n",
    "                if not np.all(sid):\n",
    "                    print(l)\n",
    "                    raise Exception('file corrupted: SVID not found')\n",
    "#             break\n",
    "    print('file %s is good' %path)\n",
    "\n",
    "            \n",
    "afterCheck(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file C:\\GFApps\\TDSParsing\\AAA\\q_test is good, and sorted gz is generated\n"
     ]
    }
   ],
   "source": [
    "def afterCheckCombine(path):\n",
    "    '''\n",
    "    '''\n",
    "    p_tag = re.compile('TAG NAME=\"(.*)\" SVID=(\\d*) UNITS=\"(.*)\"')\n",
    "    p_td = re.compile('TD TS=(.*) SV={(.*)}') \n",
    "    tags, ts_val, last_ts, gz_out, tags_out = {}, '', None, [], {}\n",
    "    with open(path) as f:\n",
    "        for l in f.readlines():\n",
    "            ts, line, fid = l.split('\\t')\n",
    "            if line.startswith('TAG'):\n",
    "                tag, svid, unit = p_tag.match(line).groups()\n",
    "                tags[svid] = tag         \n",
    "                tags_out[int(svid)] = line\n",
    "#                 print(tag,svid,unit)\n",
    "            \n",
    "            if line.startswith('TD'):\n",
    "                # write tag into gz_out buffer, if any\n",
    "                if tags_out:\n",
    "                    gz_out += [tags_out[x] for x in sorted(tags_out)]\n",
    "                    tags_out = {}\n",
    "                    \n",
    "                # sanity check for current timestamp\n",
    "                ts, vals = p_td.match(line).groups()\n",
    "                sid = [v.split('=')[0] in tags for v in vals.split('^')]\n",
    "                if not np.all(sid):\n",
    "                    print(l)\n",
    "                    raise Exception('file corrupted: SVID not found')\n",
    "                \n",
    "                # write TD line with previous timestamp\n",
    "                if ts_val and ts!=last_ts:\n",
    "                    gz_out.append('TD TS=%s SV={%s}' %(last_ts, ts_val.strip('^')))\n",
    "                    ts_val = vals\n",
    "                else:\n",
    "                    ts_val += ('^' + vals)\n",
    "                \n",
    "                # update timestamp before move to next line\n",
    "                last_ts = ts\n",
    "                \n",
    "        # last row\n",
    "        if ts_val:\n",
    "            gz_out.append('TD TS=%s SV={%s}' %(last_ts, ts_val.strip('^')))\n",
    "                    \n",
    "    with gzip.open(path+'_check.gz', 'wb') as f:\n",
    "        f.write('\\n'.join(gz_out))\n",
    "\n",
    "    print('file %s is good, and sorted gz is generated' %path)\n",
    "    \n",
    "path = 'C:\\GFApps\\TDSParsing\\AAA\\q_test_1'\n",
    "afterCheckCombine(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Hive query with collect_set\n",
    "\n",
    "bin/hive -e \"select ts, **collect_set**(data) as ts_data from tds_parsing.trace where context='EPI1200_CHD' and day in ('2016-08-17') and fid in ('20160817090432846','20160817092432121') and ((ts>='2016-08-17 09:03:21.909' and ts<='2016-08-17 09:21:14.7') or data like 'TAG%') group by ts order by ts;\" > q_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file C:\\GFApps\\TDSParsing\\AAA\\q_test_2 is good, and sorted gz is generated\n",
      "--- 2.1850001812 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def postCheck(path):\n",
    "    '''\n",
    "    '''\n",
    "    gz_out, svid = [], []\n",
    "    p_td = re.compile('\"TD TS=(.*) SV={(.*)}\"')\n",
    "    p_tag = re.compile('TAG NAME=\"(.*)\" SVID=(\\d*) UNITS=\"(.*)')\n",
    "    with open(path) as f:\n",
    "        for l in f.readlines():\n",
    "            tsd = np.array(l.split('\\t')[1].strip()[1:-1].split(','))\n",
    "            \n",
    "            # check tag\n",
    "            isTag = np.array([x.startswith('\"TAG') for x in tsd])\n",
    "            if np.any(isTag):                     \n",
    "                newTag = [x[1:-1].replace('\\\\','') for x in tsd[isTag]]\n",
    "                gz_out += newTag\n",
    "                svid += [p_tag.match(x).groups()[1] for x in newTag]\n",
    "                \n",
    "            # check td\n",
    "            isTd = ~isTag\n",
    "            if np.any(isTd):\n",
    "                svs = tsd[isTd]\n",
    "                val = [p_td.match(x).groups()[1].replace('\\\\','') for x in svs]\n",
    "                # check if svid number is defined\n",
    "                if not np.all([np.all([x.split('=')[0] in svid for x in v.split('^')]) for v in val]):\n",
    "                    print(l)\n",
    "                    raise Exception('file is corrupted, svid definition not found')\n",
    "                # insert in gz out                \n",
    "                gz_out.append('TD TS=%s SV={%s}' %(p_td.match(svs[0]).groups()[0], '^'.join(val)))\n",
    "    \n",
    "    while gz_out[-1].startswith('TAG'):\n",
    "        gz_out = gz_out[:-1]\n",
    "    \n",
    "    with gzip.open(path + '_check.gz', 'wb') as f:\n",
    "        f.write('\\n'.join(gz_out))\n",
    "        \n",
    "    print('file %s is good, and sorted gz is generated' %path)\n",
    "    \n",
    "path = 'C:\\GFApps\\TDSParsing\\AAA\\q_test_2'\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "postCheck(path)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBase Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://github.com/eleme/thriftpy/issues/234\n",
    "import happybase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hbase thrift start -threadpool\n",
    "connection = happybase.Connection('fc8xsiteg04', 9090)\n",
    "connection.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = connection.table('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cf:b': 'value2'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.row(b'row2', columns=[b'cf:b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table.put(b'row4', {b'cf2:c1': b'value1', b'cf2:c2': b'value2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cf2:c1': 'value1', 'cf2:c2': 'value2', 'cf:c1': 'value1', 'cf:c2': 'value2'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.row(b'row4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cf': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'cf:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'cf2': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'cf2:',\n",
       "  'time_to_live': 2147483647}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.families()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBase Insert with REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip, re, time\n",
    "import numpy as np\n",
    "from starbase import Connection\n",
    "from datetime import datetime\n",
    "\n",
    "gz1 = \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822033914352.TDS.gz\"\n",
    "\n",
    "def tds_hbase_insert(gz_path):\n",
    "    '''\n",
    "    read raw TDS file from ETC, and insert data into HBase\n",
    "    '''\n",
    "\n",
    "    # hbase connection\n",
    "    # hbase rest start\n",
    "    c = Connection(host='fc8xsiteg04', port=8080)\n",
    "    etc_table = c.table(gz_path.split('\\\\')[-1].split('-')[0])\n",
    "    if not etc_table.exists():\n",
    "        etc_table.create('ETC_Stats')\n",
    "        print 'created new table %s' %etc_table.name\n",
    "        \n",
    "    epoch = datetime.utcfromtimestamp(0)\n",
    "    p_tag = re.compile('TAG NAME=\"(.*)\" SVID=(\\d*) UNITS=\"(.*)\"')\n",
    "    p_td = re.compile('TD TS=(.*) SV={(.*)}')\n",
    "    \n",
    "    svid, n_svid, batch = {}, 0, {}\n",
    "    i, tot = 1, 0\n",
    "    with gzip.open(gz_path, 'rb') as f:        \n",
    "        for l in f.read().split('\\n'):   \n",
    "            # buffering tag\n",
    "            if l.startswith('TAG'):       \n",
    "                tag, sid, unit = p_tag.match(l).groups()\n",
    "                tag_elem = tag.split('/')\n",
    "                ctx = '_'.join([x.split(':')[1] for x in tag_elem[1 if len(tag_elem)>2 else 0:-1]]) \n",
    "                svid[sid] = {'context':ctx, 'sensor':tag_elem[-1], 'etc':tag_elem[0].split(':')[1]}\n",
    "                                \n",
    "            # parsing value line\n",
    "            if l.startswith('TD'):    \n",
    "                timestamp, sv = p_td.match(l).groups()\n",
    "                timestamp = datetime.strptime(timestamp, '%Y/%m/%d-%H:%M:%S.%f')\n",
    "                timestamp = int((timestamp - epoch).total_seconds() * 1000)\n",
    "                if timestamp not in batch:\n",
    "                    batch[timestamp] = {}\n",
    "                for x in svid.values():\n",
    "                    if x['context'] not in batch[timestamp]:\n",
    "                        batch[timestamp][x['context']] = {}\n",
    "                i += 1        \n",
    "                # check if all values from the same chamber, write value line\n",
    "                for val in sv.split('^'):\n",
    "                    s,v = val.split('=')                    \n",
    "                    batch[timestamp][svid[s]['context']][svid[s]['sensor']] = v.strip('\"')\n",
    "                \n",
    "            # batch insert\n",
    "            if i%20000==0:\n",
    "#                 print(i,n_svid,len(svid))\n",
    "                # add new columns                 \n",
    "                if len(svid) > n_svid:\n",
    "                    cf = etc_table.columns()\n",
    "                    ctx = np.unique([x['context'] for x in svid.values()])                    \n",
    "                    newCol = [col for col in ctx if col not in cf]\n",
    "                    if newCol:                        \n",
    "                        cmd = \"etc_table.add_columns('%s')\" %(\"','\".join(newCol))\n",
    "                        exec(cmd)\n",
    "                        time.sleep(10)\n",
    "                        print 'added new column family: %s' %str(newCol)\n",
    "                    \n",
    "                    n_svid = len(svid)  \n",
    "                    \n",
    "                # insert data\n",
    "                b = etc_table.batch()\n",
    "                if b:\n",
    "                    for row, data in batch.items():\n",
    "                        b.insert(str(row), data)\n",
    "                    b.commit(finalize=True)                                      \n",
    "                print 'batch inserted %d rows!' %len(batch)\n",
    "                tot += len(batch)\n",
    "                batch = {} \n",
    "#                 time.sleep(30)\n",
    "        \n",
    "        # insert what's left\n",
    "        if batch:\n",
    "            b = etc_table.batch()\n",
    "            if b:\n",
    "                for row, data in batch.items():\n",
    "                    b.insert(str(row), data)\n",
    "                b.commit(finalize=True)                                                      \n",
    "            \n",
    "    tot += len(batch)\n",
    "    print 'Done inserting for \"%s\" with total %d rows.' %(gz_path, tot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch inserted 788 rows!\n",
      "batch inserted 740 rows!\n",
      "batch inserted 811 rows!\n",
      "batch inserted 813 rows!\n",
      "added new column family: ['SWLLA_SWLLA8']\n",
      "batch inserted 758 rows!\n",
      "added new column family: ['SWLLA_SWLLA6']\n",
      "batch inserted 849 rows!\n",
      "batch inserted 750 rows!\n",
      "batch inserted 782 rows!\n",
      "batch inserted 808 rows!\n",
      "batch inserted 791 rows!\n",
      "batch inserted 698 rows!\n",
      "batch inserted 881 rows!\n",
      "added new column family: ['SWLLA_SWLLA9']\n",
      "batch inserted 776 rows!\n",
      "added new column family: ['SWLLA_SWLLA7']\n",
      "batch inserted 806 rows!\n",
      "Done inserting for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817092432121.TDS.gz\" with total 11159 rows.\n"
     ]
    }
   ],
   "source": [
    "gz = \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160603002414090.TDS.gz\"\n",
    "gz = \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817092432121.TDS.gz\"\n",
    "tds_hbase_insert(gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBase insert with Thrift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip, re, time, happybase, starbase\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "gz1 = \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822033914352.TDS.gz\"\n",
    "\n",
    "def add_column(etc, newCol):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    table = starbase.Connection('fc8xsiteg03', port=8080).table(etc)    \n",
    "    if newCol:                        \n",
    "        cmd = \"table.add_columns('%s')\" %(\"','\".join(newCol))\n",
    "        exec(cmd)\n",
    "        time.sleep(5)\n",
    "        print 'added new column family: %s' %str(newCol)\n",
    "\n",
    "def tds_hbase_insert_thrift(gz_path):\n",
    "    '''\n",
    "    read raw TDS file from ETC, and insert data into HBase\n",
    "    '''\n",
    "\n",
    "    # hbase connection\n",
    "    # hbase thrift start -threadpool\n",
    "    c = happybase.Connection(host='fc8xsiteg04', port=9090)    \n",
    "    etc = gz_path.split('\\\\')[-1].split('-')[0]\n",
    "    etc_table = c.table(etc)\n",
    "    if etc not in c.tables():\n",
    "        c.create_table(etc, {'ETC_Stats':dict(max_versions=1)})       \n",
    "        print 'created new table %s' %etc_table.name\n",
    "        \n",
    "    epoch = datetime.utcfromtimestamp(0)\n",
    "    p_tag = re.compile('TAG NAME=\"(.*)\" SVID=(\\d*) UNITS=\"(.*)\"')\n",
    "    p_td = re.compile('TD TS=(.*) SV={(.*)}')\n",
    "    \n",
    "    svid, n_svid, batch = {}, 0, {}\n",
    "    i, tot = 1, 0\n",
    "    with gzip.open(gz_path, 'rb') as f:        \n",
    "        for l in f.read().split('\\n'):   \n",
    "            # buffering tag\n",
    "            if l.startswith('TAG'):       \n",
    "                tag, sid, unit = p_tag.match(l).groups()\n",
    "                tag_elem = tag.split('/')\n",
    "                ctx = '_'.join([x.split(':')[1] for x in tag_elem[1 if len(tag_elem)>2 else 0:-1]]) \n",
    "                svid[sid] = {'context':ctx, 'sensor':tag_elem[-1], 'etc':tag_elem[0].split(':')[1]}\n",
    "                                \n",
    "            # parsing value line\n",
    "            if l.startswith('TD'):    \n",
    "                i += 1\n",
    "                timestamp, sv = p_td.match(l).groups()\n",
    "                timestamp = datetime.strptime(timestamp, '%Y/%m/%d-%H:%M:%S.%f')\n",
    "                timestamp = int((timestamp - epoch).total_seconds() * 1000)\n",
    "                if timestamp not in batch:\n",
    "                    batch[timestamp] = {}                \n",
    "                # check if all values from the same chamber, write value line\n",
    "                for val in sv.split('^'):\n",
    "                    s,v = val.split('=')                    \n",
    "                    batch[timestamp][(svid[s]['context']+':'+svid[s]['sensor']).encode()] = v.strip('\"').encode()\n",
    "                \n",
    "            # batch insert\n",
    "            if i%15000==0:\n",
    "                # add new columns                 \n",
    "                if len(svid) > n_svid:\n",
    "                    ctx = np.unique([x['context'] for x in svid.values()])\n",
    "                    cf = etc_table.families().keys()                    \n",
    "                    newCol = [f for f in ctx if f not in cf]\n",
    "                    if newCol:\n",
    "                        add_column(etc, newCol)\n",
    "                        c = happybase.Connection(host='fc8xsiteg04', port=9090)  \n",
    "                        etc_table = c.table(etc)\n",
    "                    n_svid = len(svid)  \n",
    "                    \n",
    "                # insert data\n",
    "                b = etc_table.batch()\n",
    "                for row, data in batch.items():\n",
    "                    b.put(str(row).encode(), data)\n",
    "                b.send()                                  \n",
    "                print 'batch inserted %d rows!' %len(batch)\n",
    "                tot += len(batch)\n",
    "                batch = {} \n",
    "#                 time.sleep(30)\n",
    "        \n",
    "        # insert what's left\n",
    "        if batch:\n",
    "            b = etc_table.batch()            \n",
    "            for row, data in batch.items():\n",
    "                b.put(str(row).encode(), data)\n",
    "            b.send()                                               \n",
    "            \n",
    "    tot += len(batch)\n",
    "    c.close()\n",
    "    print 'Done inserting for \"%s\" with total %d rows.' %(gz_path, tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch inserted 562 rows!\n",
      "batch inserted 626 rows!\n",
      "batch inserted 566 rows!\n",
      "batch inserted 554 rows!\n",
      "batch inserted 638 rows!\n",
      "batch inserted 576 rows!\n",
      "batch inserted 587 rows!\n",
      "batch inserted 640 rows!\n",
      "batch inserted 572 rows!\n",
      "batch inserted 615 rows!\n",
      "batch inserted 573 rows!\n",
      "batch inserted 565 rows!\n",
      "batch inserted 617 rows!\n",
      "batch inserted 563 rows!\n",
      "batch inserted 627 rows!\n",
      "batch inserted 552 rows!\n",
      "batch inserted 551 rows!\n",
      "batch inserted 624 rows!\n"
     ]
    },
    {
     "ename": "timeout",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6650b7d80f44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822021511047.TDS.gz\"\u001b[0m \u001b[0;31m#52100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtds_hbase_insert_thrift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-4b573ce20e76>\u001b[0m in \u001b[0;36mtds_hbase_insert_thrift\u001b[0;34m(gz_path)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m'batch inserted %d rows!'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mtot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\leyang\\appdata\\local\\continuum\\anaconda\\lib\\site-packages\\happybase\\batch.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m                      self._table.name, self._mutation_count, len(bms))\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timestamp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutateRows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             self._table.connection.client.mutateRowsTs(\n",
      "\u001b[0;32mc:\\users\\leyang\\appdata\\local\\continuum\\anaconda\\lib\\site-packages\\thriftpy\\thrift.pyc\u001b[0m in \u001b[0;36m_req\u001b[0;34m(self, _api, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# wait result only if non-oneway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"oneway\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\leyang\\appdata\\local\\continuum\\anaconda\\lib\\site-packages\\thriftpy\\thrift.pyc\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, _api)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrseqid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iprot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_message_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTMessageType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTApplicationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\leyang\\appdata\\local\\continuum\\anaconda\\lib\\site-packages\\thriftpy\\protocol\\binary.pyc\u001b[0m in \u001b[0;36mread_message_begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_message_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         api, ttype, seqid = read_message_begin(\n\u001b[0;32m--> 372\u001b[0;31m             self.trans, strict=self.strict_read)\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\leyang\\appdata\\local\\continuum\\anaconda\\lib\\site-packages\\thriftpy\\protocol\\binary.pyc\u001b[0m in \u001b[0;36mread_message_begin\u001b[0;34m(inbuf, strict)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_message_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_i32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mVERSION_MASK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\leyang\\appdata\\local\\continuum\\anaconda\\lib\\site-packages\\thriftpy\\transport\\__init__.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, sz)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreadall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\leyang\\appdata\\local\\continuum\\anaconda\\lib\\site-packages\\thriftpy\\transport\\__init__.pyc\u001b[0m in \u001b[0;36mreadall\u001b[0;34m(read_fn, sz)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mhave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mhave\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mhave\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbuff\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\leyang\\appdata\\local\\continuum\\anaconda\\lib\\site-packages\\thriftpy\\transport\\buffered\\__init__.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, sz)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buf_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\leyang\\appdata\\local\\continuum\\anaconda\\lib\\site-packages\\thriftpy\\transport\\socket.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, sz)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mbuff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             if (e.args[0] == errno.ECONNRESET and\n",
      "\u001b[0;31mtimeout\u001b[0m: timed out"
     ]
    }
   ],
   "source": [
    "gz = \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\821\\EPI1200-20160822013313558.TDS.gz\" #52100\n",
    "tds_hbase_insert_thrift(gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ETC_Stats': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'ETC_Stats:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'PM1L': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'PM1L:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'PM1R': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'PM1R:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'PM2L': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'PM2L:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'PM2R': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'PM2R:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'PM3L': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'PM3L:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'PM3R': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'PM3R:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'PM4L': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'PM4L:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'PM4R': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'PM4R:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'SNK1551': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'SNK1551:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'test1': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'test1:',\n",
       "  'time_to_live': 2147483647},\n",
       " 'test2': {'block_cache_enabled': True,\n",
       "  'bloom_filter_nb_hashes': 0,\n",
       "  'bloom_filter_type': 'ROW',\n",
       "  'bloom_filter_vector_size': 0,\n",
       "  'compression': 'NONE',\n",
       "  'in_memory': False,\n",
       "  'max_versions': 1,\n",
       "  'name': 'test2:',\n",
       "  'time_to_live': 2147483647}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=happybase.Connection('fc8xsiteg04', port=9090)\n",
    "tbl = c.table('SNK1551')\n",
    "tbl.families()\n",
    "# c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(aaa.encode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
