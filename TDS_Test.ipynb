{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path1 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\MDX4806-20160817081259226.TDS'\n",
    "path2 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX4806\\MDX4806-20160817095942791.TDS'\n",
    "gz1 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\SNK1551-20160602193817305.TDS.gz'\n",
    "\n",
    "def transform_tds(gz_path):\n",
    "    '''\n",
    "    transform gz TDS file with desired format for Hive\n",
    "    '''\n",
    "    tags, svid = [], {}\n",
    "    with gzip.open(gz_path, 'rb') as f:        \n",
    "        with open(gz_path[0:-6]+'txt', 'w') as fw:\n",
    "#             fw.write('%s\\t%s\\t%s\\n' %('timestamp', 'context', 'data')) -- no need for hive\n",
    "            for l in f.read().split('\\n'):                \n",
    "                elem = l.split(' ')\n",
    "                # buffering tag\n",
    "                if l.startswith('TAG'):                    \n",
    "                    ctx = elem[1][6:elem[1].rfind('/')].replace('Eqp:','').replace('PA:','').replace('SPA:','')\n",
    "                    svid[elem[2][5:]] = ctx\n",
    "                    tags.append((l,ctx))\n",
    "                # parsing value line\n",
    "                if l.startswith('TD'):                    \n",
    "                    ts = elem[1][3:].replace('-',' ').replace('/','-')\n",
    "                    # write buffered tag line with timestamp and context\n",
    "                    for t,ctx in tags:\n",
    "                        fw.write('%s\\t%s\\t%s' %(ts, ctx, t))\n",
    "                    tags = []\n",
    "                    # write value line\n",
    "                    sn = elem[2][4:-1].split('^')[0].split('=')[0]                \n",
    "                    fw.write('%s\\t%s\\t%s' %(ts, svid[sn], l))\n",
    "    print 'TDS transform completed!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "gz1 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\SNK1551-20160602193817305.TDS.gz'\n",
    "gz2 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\ETX4800-20160817091159382.TDS.gz'\n",
    "\n",
    "def transform_tds_gz(gz_path):\n",
    "    '''\n",
    "    transform gz TDS file with desired format for Hive\n",
    "    '''\n",
    "    tags, svid, gz_out = [], {}, []\n",
    "    with gzip.open(gz_path, 'rb') as f:        \n",
    "        for l in f.read().split('\\n'):                \n",
    "            elem = l.split(' ')\n",
    "            # buffering tag\n",
    "            if l.startswith('TAG'):                    \n",
    "                ctx = elem[1][6:elem[1].rfind('/')].replace('Eqp:','').replace('PA:','').replace('SPA:','').replace('/','_')\n",
    "                svid[elem[-2][5:]] = ctx\n",
    "                tags.append((l,ctx))\n",
    "            # parsing value line\n",
    "            if l.startswith('TD'):                    \n",
    "                ts = elem[1][3:].replace('-',' ').replace('/','-')\n",
    "                # write buffered tag line with timestamp and context\n",
    "                for t,ctx in tags:\n",
    "                    gz_out.append('%s\\t%s\\t%s' %(ts, ctx, t))\n",
    "                tags = []\n",
    "                # write value line\n",
    "                sn = elem[2][4:-1].split('^')[0].split('=')[0]                \n",
    "                gz_out.append('%s\\t%s\\t%s' %(ts, svid[sn], l))\n",
    "            \n",
    "    with gzip.open(gz_path[0:-6]+'gz', 'wb') as f:\n",
    "        f.write('\\n'.join(gz_out))\n",
    "    print 'TDS transform completed for %s' %gz_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-08-17 08:02:19.621',\n",
       " 'MDX4806/CHD',\n",
       " 'TD TS=2016/08/17-08:02:19.621 SV={3=0^4=-1^5=29.741^6=\"HEAT\"^7=3^8=0.656^9=309^10=16.5678884243294^11=-0.06^12=1800^13=8.054^14=3.27413814835256E-05^15=7.498779296875^16=3.736^17=-0.000367^18=-2.3E-05^19=-0.000397^20=-3.3E-05^21=0.000227^22=3.4E-05^23=-4.6E-05^24=0.000139}']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d='2016/08/17-08:02:19.621\tMDX4806/CHD\tTAG NAME=\"Eqp:MDX4806/PA:CHD/BR2_LCF--rCfXCorrExt\" SVID=21 UNITS=\"m\"'\n",
    "e='timestamp\tcontext\tdata'\n",
    "f='2016-08-17 08:02:19.621\tMDX4806/CHD\tTD TS=2016/08/17-08:02:19.621 SV={3=0^4=-1^5=29.741^6=\"HEAT\"^7=3^8=0.656^9=309^10=16.5678884243294^11=-0.06^12=1800^13=8.054^14=3.27413814835256E-05^15=7.498779296875^16=3.736^17=-0.000367^18=-2.3E-05^19=-0.000397^20=-3.3E-05^21=0.000227^22=3.4E-05^23=-4.6E-05^24=0.000139}'\n",
    "f.split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDS transform completed for C:\\Users\\leyang\\Downloads\\AAA_MDX\\ETX4800-20160817091159382.TDS.gz\n",
      "--- 1.21299982071 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "transform_tds_gz(gz2)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='TD TS=2016/08/17-08:02:19.621 SV={3=0^4=-1^5=29.741^6=\"HEAT\"^7=3^8=0.656^9=309^10=16.5678884243294^11=-0.06^12=1800^13=8.054^14=3.27413814835256E-05^15=7.498779296875^16=3.736^17=-0.000367^18=-2.3E-05^19=-0.000397^20=-3.3E-05^21=0.000227^22=3.4E-05^23=-4.6E-05^24=0.000139}'\n",
    "b='TD TS=2016/08/17-08:02:19.851 SV={2=\"ProcessStarted\"}'\n",
    "b='TD TS=2016/08/17-08:02:19.861 SV={1=0}'\n",
    "b.split(' ')[2][4:-1].split('^')[0].split('=')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "with gzip.open('C:\\Users\\leyang\\Downloads\\AAA_MDX\\SNK1551-20160602193817305.TDS.gz', 'rb') as f:\n",
    "    file_content = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip, re\n",
    "import numpy as np\n",
    "\n",
    "sample_tag = 'TAG NAME=\"Eqp:SNK1551/PA:PM3L/ExhaustPressure02\" SVID=58 UNITS=\"\"'\n",
    "sample_td = ' TD TS=2016/06/02-23:12:35.714 SV={191=\"SNK1551-20160602-0032\"^192=\"UR62192.000\"^193=\"rcp P-SC-50DHF-180TMAH-5L20P\"^194=\"D-P-SNK155X. P-SC-50DHF-180TMAH-HS.01\"^195=\"21\"^196=\"PMGYB060MXA7\"^198=1^201=1}'\n",
    "\n",
    "p_tag = re.compile('TAG NAME=\"Eqp:(.*)\" SVID=(\\d*) UNITS=\"(.*)\"')\n",
    "p_td = re.compile('TD TS=(.*) SV={(.*)}')\n",
    "\n",
    "gz1 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\SNK1551-20160602193817305.TDS.gz'\n",
    "\n",
    "def check_tds_gz(gz_path):\n",
    "    '''\n",
    "    transform gz TDS file with desired format for Hive\n",
    "    '''\n",
    "    tags, svid, gz_out, cnt = [], {}, [], 0\n",
    "    fid = gz_path[gz_path.index('-')+1:-7]\n",
    "    with gzip.open(gz_path, 'rb') as f:        \n",
    "        for l in f.read().split('\\n'):   \n",
    "            # buffering tag\n",
    "            if l.startswith('TAG'):       \n",
    "                p1, p2 = l.index('\" SVID='), l.index(' UNITS=\"')\n",
    "                tag, sid = l[10:p1], l[p1+7:p2]\n",
    "                ctx = tag[:tag.rfind('/')].replace('Eqp:','').replace('PA:','').replace('SPA:','').replace('/','_')\n",
    "                svid[sid] = ctx\n",
    "                tags.append((l,ctx))\n",
    "            # parsing value line\n",
    "            if l.startswith('TD'):                    \n",
    "                p1 = l.index(' SV=')\n",
    "                timestamp, sv = l[6:p1], l[p1+1:]                \n",
    "                ts = timestamp.replace('-',' ').replace('/','-')\n",
    "                # write buffered tag line with timestamp and context\n",
    "                for t,ctx in tags:\n",
    "#                     print '%s\\t%s\\t%s\\t%s' %(ts, ctx, fid, t)\n",
    "                    gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, ctx, fid, t))\n",
    "                tags = []\n",
    "                # check if all values from the same chamber, write value line\n",
    "                values = np.array(sv[4:-1].split('^'))\n",
    "                sn = np.array([svid[kv.split('=')[0]] for kv in values])\n",
    "                # split the TD row for individual chamber\n",
    "                a_ctx = np.unique(sn)                \n",
    "                if a_ctx.size > 1:\n",
    "                    cnt += 1\n",
    "#                     print (timestamp, a_ctx.size)\n",
    "                    for ctx in a_ctx:\n",
    "                        td = 'TD TS=%s SV={%s}' %(timestamp, '^'.join(values[sn==ctx]).strip('}'))\n",
    "                        gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, ctx, fid, td))\n",
    "                else:\n",
    "                    gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, a_ctx[0], fid, l))\n",
    "            \n",
    "    with gzip.open(gz_path[0:-6]+'gz', 'wb') as f:\n",
    "        f.write('\\n'.join(gz_out))\n",
    "    print 'TDS transform completed for \"%s\", with %d mixing TD lines.' %(gz_path, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\BBB\\MDX4806\\MDX4806-20160817080219812.TDS.gz\", with 3205 mixing TD lines.\n"
     ]
    }
   ],
   "source": [
    "gz2 = 'C:\\GFApps\\TDSParsing\\AAA\\ETX4800\\ETX4800-20160817075058359.TDS.gz'\n",
    "gz3 = 'C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817090432846.TDS.gz'\n",
    "gz4 = 'C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602202022427.TDS.gz'\n",
    "gz5 = 'C:\\GFApps\\TDSParsing\\BBB\\MDX4806\\MDX4806-20160817080219812.TDS.gz'\n",
    "check_tds_gz(gz5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602193817305.TDS.gz\", with 1 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602195917496.TDS.gz\", with 2 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602202022427.TDS.gz\", with 2 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602204112409.TDS.gz\", with 4 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602210222502.TDS.gz\", with 5 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602212201047.TDS.gz\", with 3 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602215613444.TDS.gz\", with 2 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602221723473.TDS.gz\", with 3 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602223818508.TDS.gz\", with 6 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602225923363.TDS.gz\", with 5 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602232024726.TDS.gz\", with 3 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602234113623.TDS.gz\", with 4 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160602235008793.TDS.gz\", with 0 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160603002414090.TDS.gz\", with 3 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160603004421775.TDS.gz\", with 3 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160603010517903.TDS.gz\", with 1 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\SNK1551-20160603012626850.TDS.gz\", with 3 mixing TD lines.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = 'C:\\GFApps\\TDSParsing\\AAA\\SNK1551\\\\'\n",
    "\n",
    "for f in os.listdir(folder):\n",
    "    if not f.endswith('.TDS.gz'):\n",
    "        continue\n",
    "    check_tds_gz(folder + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'asdfsfaf'\n",
    "s.endswith('af')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another way of parsing using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip, re\n",
    "import numpy as np\n",
    "\n",
    "gz1 = 'C:\\Users\\leyang\\Downloads\\AAA_MDX\\SNK1551-20160602193817305.TDS.gz'\n",
    "\n",
    "def check_tds_gz(gz_path):\n",
    "    '''\n",
    "    transform gz TDS file with desired format for Hive\n",
    "    '''\n",
    "    p_tag = re.compile('TAG NAME=\"(.*)\" SVID=(\\d*) UNITS=\"(.*)\"')\n",
    "    p_td = re.compile('TD TS=(.*) SV={(.*)}')\n",
    "    \n",
    "    tags, svid, gz_out, cnt = [], {}, [], 0\n",
    "    fid = gz_path[gz_path.index('-')+1:-7]\n",
    "    with gzip.open(gz_path, 'rb') as f:        \n",
    "        for l in f.read().split('\\n'):   \n",
    "            # buffering tag\n",
    "            if l.startswith('TAG'):       \n",
    "                tag, sid, unit = p_tag.match(l).groups()\n",
    "                ctx = '_'.join([x.split(':')[1] for x in tag.split('/')[:-1]])\n",
    "                svid[sid] = ctx\n",
    "                tags.append((l, ctx))\n",
    "            # parsing value line\n",
    "            if l.startswith('TD'):    \n",
    "                timestamp, sv = p_td.match(l).groups()\n",
    "                ts = timestamp.replace('-',' ').replace('/','-')\n",
    "                # write buffered tag line with timestamp and context\n",
    "                for t,ctx in tags:\n",
    "                    gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, ctx, fid, t))\n",
    "                tags = []\n",
    "                # check if all values from the same chamber, write value line\n",
    "                values = np.array(sv.split('^'))\n",
    "                sn = np.array([svid[kv.split('=')[0]] for kv in values])\n",
    "                # split the TD row for individual chamber\n",
    "                a_ctx = np.unique(sn)                \n",
    "                if a_ctx.size > 1:\n",
    "                    cnt += 1\n",
    "#                     print (timestamp, a_ctx.size)\n",
    "                    for ctx in a_ctx:\n",
    "                        td = 'TD TS=%s SV={%s}' %(timestamp, '^'.join(values[sn==ctx]))\n",
    "                        gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, ctx, fid, td))\n",
    "                else:\n",
    "                    gz_out.append('%s\\t%s\\t%s\\t%s' %(ts, a_ctx[0], fid, l))\n",
    "            \n",
    "    with gzip.open(gz_path[0:-6]+'gz', 'wb') as f:\n",
    "        f.write('\\n'.join(gz_out))\n",
    "    print 'Done for \"%s\", with %d mixing TD lines.' %(gz_path, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817080228263.TDS.gz\", with 89 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817082332300.TDS.gz\", with 84 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817084332846.TDS.gz\", with 82 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817090432846.TDS.gz\", with 103 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817092432121.TDS.gz\", with 98 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817094431522.TDS.gz\", with 92 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817102532613.TDS.gz\", with 106 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817104632629.TDS.gz\", with 103 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817110732622.TDS.gz\", with 106 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817112835377.TDS.gz\", with 106 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817114932601.TDS.gz\", with 107 mixing TD lines.\n",
      "TDS transform completed for \"C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\EPI1200-20160817121035273.TDS.gz\", with 99 mixing TD lines.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = 'C:\\GFApps\\TDSParsing\\AAA\\EPI1200\\\\'\n",
    "\n",
    "for f in os.listdir(folder):\n",
    "    if not f.endswith('.TDS.gz'):\n",
    "        continue\n",
    "    check_tds_gz(folder + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive result sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file C:\\GFApps\\TDSParsing\\AAA\\q_test is good\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "aaa = '2016-08-17 08:43:30.681\tTAG NAME=\"Eqp:EPI1200/PA:CHD/BottomPyrometerValue\" SVID=447 UNITS=\"\"\t20160817090432846'\n",
    "\n",
    "aaa.split('\\t')\n",
    "\n",
    "path = 'C:\\GFApps\\TDSParsing\\AAA\\q_test'\n",
    "\n",
    "def afterCheck(path):\n",
    "    '''\n",
    "    '''\n",
    "    p_tag = re.compile('TAG NAME=\"(.*)\" SVID=(\\d*) UNITS=\"(.*)\"')\n",
    "    p_td = re.compile('TD TS=(.*) SV={(.*)}') \n",
    "    tags = {}\n",
    "    with open(path) as f:\n",
    "        for l in f.readlines():\n",
    "            ts, line, fid = l.split('\\t')\n",
    "            if line.startswith('TAG'):\n",
    "                tag, svid, unit = p_tag.match(line).groups()\n",
    "                tags[svid] = tag            \n",
    "#                 print(tag,svid,unit)\n",
    "            if line.startswith('TD'):\n",
    "                ts, vals = p_td.match(line).groups()\n",
    "                sid = [v.split('=')[0] in tags for v in vals.split('^')]\n",
    "                if not np.all(sid):\n",
    "                    print(l)\n",
    "                    raise Exception('file corrupted: SVID not found')\n",
    "#             break\n",
    "    print('file %s is good' %path)\n",
    "\n",
    "            \n",
    "afterCheck(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file C:\\GFApps\\TDSParsing\\AAA\\q_test is good, and sorted gz is generated\n"
     ]
    }
   ],
   "source": [
    "def afterCheckCombine(path):\n",
    "    '''\n",
    "    '''\n",
    "    p_tag = re.compile('TAG NAME=\"(.*)\" SVID=(\\d*) UNITS=\"(.*)\"')\n",
    "    p_td = re.compile('TD TS=(.*) SV={(.*)}') \n",
    "    tags, ts_val, last_ts, gz_out, tags_out = {}, '', None, [], {}\n",
    "    with open(path) as f:\n",
    "        for l in f.readlines():\n",
    "            ts, line, fid = l.split('\\t')\n",
    "            if line.startswith('TAG'):\n",
    "                tag, svid, unit = p_tag.match(line).groups()\n",
    "                tags[svid] = tag         \n",
    "                tags_out[int(svid)] = line\n",
    "#                 print(tag,svid,unit)\n",
    "            \n",
    "            if line.startswith('TD'):\n",
    "                # write tag into gz_out buffer, if any\n",
    "                if tags_out:\n",
    "                    gz_out += [tags_out[x] for x in sorted(tags_out)]\n",
    "                    tags_out = {}\n",
    "                    \n",
    "                # sanity check for current timestamp\n",
    "                ts, vals = p_td.match(line).groups()\n",
    "                sid = [v.split('=')[0] in tags for v in vals.split('^')]\n",
    "                if not np.all(sid):\n",
    "                    print(l)\n",
    "                    raise Exception('file corrupted: SVID not found')\n",
    "                \n",
    "                # write TD line with previous timestamp\n",
    "                if ts_val and ts!=last_ts:\n",
    "                    gz_out.append('TD TS=%s SV={%s}' %(last_ts, ts_val.strip('^')))\n",
    "                    ts_val = vals\n",
    "                else:\n",
    "                    ts_val += ('^' + vals)\n",
    "                \n",
    "                # update timestamp before move to next line\n",
    "                last_ts = ts\n",
    "                \n",
    "        # last row\n",
    "        if ts_val:\n",
    "            gz_out.append('TD TS=%s SV={%s}' %(last_ts, ts_val.strip('^')))\n",
    "                    \n",
    "    with gzip.open(path+'_check.gz', 'wb') as f:\n",
    "        f.write('\\n'.join(gz_out))\n",
    "\n",
    "    print('file %s is good, and sorted gz is generated' %path)\n",
    "    \n",
    "path = 'C:\\GFApps\\TDSParsing\\AAA\\q_test_1'\n",
    "afterCheckCombine(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Hive query with collect_set\n",
    "\n",
    "bin/hive -e \"select ts, **collect_set**(data) as ts_data from tds_parsing.trace where context='EPI1200_CHD' and day in ('2016-08-17') and fid in ('20160817090432846','20160817092432121') and ((ts>='2016-08-17 09:03:21.909' and ts<='2016-08-17 09:21:14.7') or data like 'TAG%') group by ts order by ts;\" > q_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file C:\\GFApps\\TDSParsing\\AAA\\q_test_2 is good, and sorted gz is generated\n",
      "--- 2.1850001812 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def postCheck(path):\n",
    "    '''\n",
    "    '''\n",
    "    gz_out, svid = [], []\n",
    "    p_td = re.compile('\"TD TS=(.*) SV={(.*)}\"')\n",
    "    p_tag = re.compile('TAG NAME=\"(.*)\" SVID=(\\d*) UNITS=\"(.*)')\n",
    "    with open(path) as f:\n",
    "        for l in f.readlines():\n",
    "            tsd = np.array(l.split('\\t')[1].strip()[1:-1].split(','))\n",
    "            \n",
    "            # check tag\n",
    "            isTag = np.array([x.startswith('\"TAG') for x in tsd])\n",
    "            if np.any(isTag):                     \n",
    "                newTag = [x[1:-1].replace('\\\\','') for x in tsd[isTag]]\n",
    "                gz_out += newTag\n",
    "                svid += [p_tag.match(x).groups()[1] for x in newTag]\n",
    "                \n",
    "            # check td\n",
    "            isTd = ~isTag\n",
    "            if np.any(isTd):\n",
    "                svs = tsd[isTd]\n",
    "                val = [p_td.match(x).groups()[1].replace('\\\\','') for x in svs]\n",
    "                # check if svid number is defined\n",
    "                if not np.all([np.all([x.split('=')[0] in svid for x in v.split('^')]) for v in val]):\n",
    "                    print(l)\n",
    "                    raise Exception('file is corrupted, svid definition not found')\n",
    "                # insert in gz out                \n",
    "                gz_out.append('TD TS=%s SV={%s}' %(p_td.match(svs[0]).groups()[0], '^'.join(val)))\n",
    "    \n",
    "    while gz_out[-1].startswith('TAG'):\n",
    "        gz_out = gz_out[:-1]\n",
    "    \n",
    "    with gzip.open(path + '_check.gz', 'wb') as f:\n",
    "        f.write('\\n'.join(gz_out))\n",
    "        \n",
    "    print('file %s is good, and sorted gz is generated' %path)\n",
    "    \n",
    "path = 'C:\\GFApps\\TDSParsing\\AAA\\q_test_2'\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "postCheck(path)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
